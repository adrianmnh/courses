# understanding the machine learning pipeline
; 
data set -> final model doing anlysis, interpretation and undertanding

the goal of ML :
non physical recreation of a model

metadata capture -> analysis

collect relvant data -> process it > learning algorithm

evaluate models perfomance to ensure it meets out needs

img 1

some phenomenon(source) to turn into data

incidental (natural data) 

* artificial syntehtic: mathematical obj that can generate data

* physiological symptoms, stock price drops, sequential strings

* modal captures by diff sensors

> we must go through the process of translating data into a mathematical medium for the model to use

note that noise will be present most of the time, an its up to us to decide how to minimize it

> in supervised learning model gets annotations from user

labeling may be a cmlicated initialization 66% success rate

* statistical means to input missing data

can the data be skipped? can the algorithm works with only certai feautures?

We want to preserve the # of sample we have to increase model performance
### extracting features
> is the data correct?

1.  knowing the domain helps
2.   in statistical data, sometimes the carry on or mean may be used when missing data (sometimes median)


once we have an expert annotation, then we can train a model to syphen through unknowns

* looking at different colors, sizes, lminisoty, texture
* computer seets 3 sets of numbers ( 3 matrices)

### 

regression model -> functin of some type

* Prediction vs forecast - Y/N vs regression

supervised learning.. (falls into Deep Learning)
* BURT large body of text trained model

agglo - hierarchical clustering

>  we want to test multiple models to see which fits our data best, and produces best results relevant to the data. can multiple models produce correct relevant results??

hyperparameter clustering k ... - its how the model learns the data and classifies accoridngly

reduce sample bias - n-fold cross validation

IMG 2

standard deviotion and error gap are larger the smaller the amount of data used to train model

n-fold cross val allows using data in diff permutations to ..

**Feature selection** finding meaningful data that can directly affect the result

mathematical and statistical means to decide wether data is relevant to the result

### Does the model atually meet the goals we wnat?

black box models may be biased - trivial results

> we want each class to have similar or equal amount of features to be classfied by

why de que square errors? no negative values, absolutes, minimums and maximums

pca principle component analysis

IMG 3 - is a transformed set from the 2D matrix of the iris plant. not the data we started

