<!DOCTYPE html><html lang="en" data-mode="dark" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Big Data Algorithms" /><meta property="og:locale" content="en" /><meta name="description" content="Probability Review" /><meta property="og:description" content="Probability Review" /><link rel="canonical" href="https://adrianmnh.github.io/courses/courses/bigdata/" /><meta property="og:url" content="https://adrianmnh.github.io/courses/courses/bigdata/" /><meta property="og:site_name" content="Courses" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-04-03T10:08:53-04:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Big Data Algorithms" /><meta name="twitter:site" content="@nlawliet6" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-03T10:08:53-04:00","datePublished":"2023-04-03T10:08:53-04:00","description":"Probability Review","headline":"Big Data Algorithms","mainEntityOfPage":{"@type":"WebPage","@id":"https://adrianmnh.github.io/courses/courses/bigdata/"},"url":"https://adrianmnh.github.io/courses/courses/bigdata/"}</script><title>Big Data Algorithms | Courses</title><link rel="apple-touch-icon" sizes="180x180" href="/courses/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/courses/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/courses/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/courses/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/courses/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Courses"><meta name="application-name" content="Courses"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/courses/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.2/css/all.min.css"><link rel="stylesheet" href="/courses/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/courses/" class="mx-auto"> <img src="https://raw.githubusercontent.com/adrianmnh/courses/mainBranch/assets/img/pagelogo.png" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/courses/">Courses</a></div><div class="site-subtitle font-italic">These are some notes I've accumulated over the years, self taught and Queens College student</div></div><ul class="w-100"><li class="nav-item"> <a href="/courses/" class="nav-link"> <i class="fa-fw fa-solid fa-book-open ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/courses/categories/" class="nav-link"> <i class="fa-fw fa-solid fa-book ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/courses/tags/" class="nav-link"> <i class="fa-fw fa-solid fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/courses/datamodeling/" class="nav-link"> <i class="fa-fw fa-solid fa-database ml-xl-3 mr-xl-3 unloaded"></i> <span>DATA MODELING</span> </a><li class="nav-item"> <a href="/courses/datascience/" class="nav-link"> <i class="fa-fw fa-solid fa-file-waveform ml-xl-3 mr-xl-3 unloaded"></i> <span>APPLIED DATA SCIENCE</span> </a><li class="nav-item"> <a href="/courses/computervision/" class="nav-link"> <i class="fa-fw fa-solid fa-eye ml-xl-3 mr-xl-3 unloaded"></i> <span>COMPUTER VISION</span> </a><li class="nav-item"> <a href="/courses/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item active"> <a href="/courses/bigdata/" class="nav-link"> <i class="fa-fw fa-solid fa-database ml-xl-3 mr-xl-3 unloaded"></i> <span>BIG DATA ALGORITHMS</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/adrianmnh" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/nlawliet6" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['adrian_noa','icloud.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/courses/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper"><div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4"> <span id="breadcrumb"> <span> <a href="/courses/"> Home </a> </span> <span>Big Data Algorithms</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Big Data Algorithms</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper" class="d-flex justify-content-center"><div id="main" class="container pl-xl-4 pr-xl-4"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4 pb-5"><div class="post pl-1 pr-1 pl-md-2 pr-md-2"><h1 class="dynamic-title"> Big Data Algorithms</h1><div class="post-content"><h1 id="probability-review">Probability Review</h1><h2 id="bernouli-distribution"><span class="mr-2">Bernouli Distribution</span><a href="#bernouli-distribution" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Denotes an event that takes on 2 possible values, $success(p)$ or $failure(q)$</p><p>$P(X=1)=p \ \ \ \ and\ \ \ \ P(X=0)=1-p=q$</p><p>$E(X)=p \ \ \ and\ \ \ Var(X)=pq$</p><h2 id="binomial-distribution"><span class="mr-2">Binomial Distribution</span><a href="#binomial-distribution" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Denotes the probability that a number of success or failed events take place(Bernoulis)</p><p>Satisfies:</p><ol><li>Binary outcome(Bernouli)<li>Independent<li>$n \text{ # of trials}$<li>Same probability of success or failure per trial</ol><p>$P(X=k) = {n \choose k}p^kq^{n-k} \text{ where k}\in{0,1,2,..,n}$</p><p>$E(X)=np \ \ \ \ and\ \ \ Var(X)=npq$</p><h2 id="geometric-distribution"><span class="mr-2">Geometric Distribution</span><a href="#geometric-distribution" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Used to find the probability of getting $1^{st}$ success or failure on trial $X$</p><p>Using the same conditions as Binomial Distribution</p><p>$P(X=k) = q^{k-1}p$</p><p>$E(X)=1/p \ \ \ and\ \ \ Var(X)=q/p^2$</p><h3 id="notes"><span class="mr-2"><code class="language-plaintext highlighter-rouge">notes:</code></span><a href="#notes" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>$lg(n) \rightarrow base\ 2$<li>$log(n) \rightarrow base\ 10$<li><p>$ln(n) \rightarrow base \ e$</p><li>If $\large I_A=1\ when\ x\ge t, \ then\ Pr(I=1)=Pr(x\ge t)$<li>$\text{Indicator Random Variable: ExpectedValue(}I_A \text{) is equal to prob of event A ocurring}$<ul><li>$\large E(I_A) = P(A) = p$</ul><li>Variance and Deviation $\mu$<ul><li>$\sqrt{Var(X)} = \mu$<li>$Var(X) = \mu^2$<li>$\large Var(X) = E[(X-E[X])^2]$<li>$\large Var(X) = E[X^2] - E[X]^2$</ul><li>Tail bounds<ul><li>Markov’s - $Pr(X \ge t)\leq \Large \frac{E(X)}{t}$<li>ChebyShev’s - $Pr(X \ge t) \le Pr(|X - E(X) |\ge t )\le\Large \frac{Var(X)}{t^2}$</ul></ul><p><img data-src="https://raw.githubusercontent.com/adrianmnh/courses/mainBranch/assets/img\linebreak-fire.png" alt="" data-proofer-ignore></p><h1 id="membershipdictionary-problem">Membership(Dictionary Problem)</h1><p>We want to construct an <strong>algo/data structure</strong> that stores elements in $S$ to answer membership queries</p><p><code class="language-plaintext highlighter-rouge">binary search trees(BSTs)</code></p><ul><li>Includes AVL, Red-Black, Splay trees</ul><div class="table-wrapper"><table><thead><tr><th style="text-align: center">$\phi\ BST$<th style="text-align: center">Cost<tbody><tr><td style="text-align: center">Space Cost<td style="text-align: center">$O(n\ elements \times log(n) \ bits) \approx O(n)$<tr><td style="text-align: center">Pre-Processing<td style="text-align: center">$O(n)\rightarrow \text{ proportional to # of added elements}$<tr><td style="text-align: center">Query Cost<td style="text-align: center">$lg(n)$</table></div><p>Can <strong>querying cost</strong> be reduced?</p><p><code class="language-plaintext highlighter-rouge">Hash Functions/tables/maps/compression functions</code></p><p>$h[u]\rightarrow[m]\text{ such that u is strictly larger than m } u \gg m$</p><p>$m$ is the number of buckets or slots available in array or table $T$, used to store hashed elements with $h$</p><p>Collitions arrise because $u \gg m$ so by Pigeon Hole Principle, at least 2 objects in $[u]$ map to at least 1 object in $[m]$</p><p>Hashing with chaining is used to handle collisions, pointers to linked lists on each bucket $m$ (usually inserted in the front to reduce cost)</p><p>Query time is proportional to the length of linked list of bucket $m$ in which object $x$ maps to using hash function $h$</p><ol><li>worst case: every element in $S$ maps to 1 bucket $[u]\rightarrow\ c$<li>best case: <code class="language-plaintext highlighter-rouge">simple hash function:</code> every element $i \in [u]$ is mapped uniformly at random, $h:[u]\rightarrow [m]$<ul><li>$Pr(h(i)=j)=1/m$</ul></ol><div class="table-wrapper"><table><thead><tr><th style="text-align: center">$\phi\ hash$<th style="text-align: center">Cost<tbody><tr><td style="text-align: center">Space Cost<td style="text-align: center">$O(n)$<tr><td style="text-align: center">Pre-Processing<td style="text-align: center">$O(n)$<tr><td style="text-align: center">Query Cost<td style="text-align: center">$O(n)\ …\ O(1/m)$</table></div><h2 id="simple-uniform-hash-function"><span class="mr-2">Simple <strong>Uniform</strong> Hash Function</span><a href="#simple-uniform-hash-function" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><code class="language-plaintext highlighter-rouge">Query Time Analysis and Proof</code></p><p>Let $Q$ be query time for hashing w/ chain struct $1\le Q\le n$</p><p><code class="language-plaintext highlighter-rouge">theorem:</code> assuming $h$ is uniform, the <strong>expected value or mean:</strong></p><p>$E(Q)=O(n/m)$</p><p><code class="language-plaintext highlighter-rouge">proof:</code> query time for any item $x_i$ is <strong>dependent</strong> on the # of distinct elements $x_j(j\ne i)$ that hash to the same bucket $:[m]$</p><p>This counts the number of collisions by setting probability to 1 if any to different elements map to the same bucket $[m]$, 0 otherwise</p><p>Using Indicator r.v., the fact that $\text{Pr(of element hashing to some bucket)} = \LARGE \frac{1}{m}$ and that $E(I_A)=Pr(A)$</p>\[Q(x) = \begin{cases} \ 1,\ h(x_i)=h(x_j), i \ne j \\ \ 0,\ otherwise \end{cases}\] \[\text{query time } Q = \sum_{i=1}^n E(X_i)= E\left(\sum_{i=1}^n X_i\right) = E\left(\sum_{i=1}^n \frac{1}{m}\right) = \frac{n}{m} \\ \text{in expectation, } \\ Q = \large O\left(\frac{n}{m}\right)\]<p><code class="language-plaintext highlighter-rouge">disclaimer:</code> how well a simple uniform hash performs depends on how close $m$ is to $S$. If $S \gg m$ then the linked lists will be too large to search</p><ol><li>If $m=O(n)$, then $E(Q)=O(1)$<li>Hashing w/ chaining provides $O(1)$ <strong>expected Query Time</strong> $\iff$ the # of elements in $S$ is proportional to the # of slots $[m]$<li>often more items that slots available → <code class="language-plaintext highlighter-rouge">Not the best structure</code><li>$P(Q_X)$ = Probability that $h$ uniformly hashes to bucket $[m]$</ol><div class="table-wrapper"><table><thead><tr><th style="text-align: center">$\phi\ chaining$<th style="text-align: center">Cost<tbody><tr><td style="text-align: center">Space Cost<td style="text-align: center">$O(n)$<tr><td style="text-align: center">Pre-Processing<td style="text-align: center">$O(n)$<tr><td style="text-align: center">Query Cost<td style="text-align: center">$O(1) \text{ iff proportional } S\ to\ [m]$<tr><td style="text-align: center">Query Time:<td style="text-align: center">$P(Q_X) = \Large \frac{1}{m}$<tr><td style="text-align: center">Expectation:<td style="text-align: center">$E(Q_X) = \Large\left(\frac{n}{m}\right)$</table></div><p><img data-src="https://raw.githubusercontent.com/adrianmnh/courses/mainBranch/assets/img\linebreak-fire.png" alt="" data-proofer-ignore></p><h1 id="tail-bounds"><strong>Tail Bounds</strong></h1><p>What is the probability our result will deviate from the expectation? aka <code class="language-plaintext highlighter-rouge">bad event</code></p><h2 id="markovs-inequality"><span class="mr-2"><strong>Markov’s Inequality</strong></span><a href="#markovs-inequality" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Let $X$ be a r.v. over sample space $\Omega$ then $\forall_t \in R, t&gt;0$</p><ul><li>What is the probability the <strong>actual value</strong> is beyond <strong>expected value</strong> by a factor of $t$ \(\large Pr(X\ge t.E(X)) \leq \frac{1}{t} \\ \equiv \\ Pr(X \ge t)\leq \frac{E(X)}{t}\)</ul><p><code class="language-plaintext highlighter-rouge">disclaimer:</code> Markov’s Inequality is often too weak to yield any useful results.</p><ol><li>Fundamental tool in developing more sophisticated bounds.<ul><li>Use tail bounds to control $[m]$(size of table) to get a $O(1)$ query time (in expectation).</ul><li>Techniques for bounding tail distribution are the major tool for estimating<ul><li>$Prob(failure)$ of algorithms, and<li>$High\ probability\ bounds$ on their run-time</ul></ol><p><code class="language-plaintext highlighter-rouge">proof:</code> for $t &gt; 0$, let $I_A = \begin{cases} \ 1,\ if X\ge t <br /> \ 0,\ o.w. \end{cases}$ , note that $X\ge 0$</p><p>$\text{first: Prove that } \ I_A\le X/t$</p><p>We have two possible outcomes:</p><ol><li>$I_A = 1$ if the event $X\ge t$ occurs, and<li>$I_A = 0$ if $X &lt; t$. note that $t&gt;0$</ol><p>$t.I_A \le X ⇒ t.1 \le X$ if event occurs and $t.I_A \le X ⇒ t.0 \le X$ if event does not occur</p><ol><li>$t\le X$ is <strong>true</strong><li>$0\le X$ also <strong>true</strong></ol><p>therefore, $t.I_A \le X \ \ ⇒ \ \ \large I_A\le\frac{X}{t}$</p><p>$\text{second: } \ I_A=[0,1], E(I_A) = Pr(I_A=1) = Pr(X\ge t)$</p><p>Taking expectations:</p><p>$Pr(X\ge t) = E[I_A] \text{ by linearity of expectations}$</p><p>$E[I_A] \le E[X/t]$</p><p>$E[X/t] = \frac{\large E[X]}{\large t}$</p><p>$\text{finally: } Pr(X\ge t) \le \frac{\large E[X]}{\large t}$</p><h2 id="chebyshevs-inequality"><span class="mr-2"><strong>ChebyShev’s Inequality</strong></span><a href="#chebyshevs-inequality" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Let $X$ be a r.v. over sample space $\Omega$ then $for \ \forall\ t &gt;0$</p>\[\large Pr(\ \left|X-E(X)\right| \ge t\ )\le \frac{Var[X]}{t^2}\]<p><code class="language-plaintext highlighter-rouge">disclaimer:</code> Significantly <strong>stronger tailbound</strong> using expectaion and variance of a r.v.</p><p><code class="language-plaintext highlighter-rouge">proof:</code></p><p>$\text{first: } Pr(|X-E(X)| \ge t) = Pr([X-E(X)]^2 \ge t^2)$</p><p>Since $[X-E(X)]^2$ is a non-negative r.v., apply Markov’s</p><p>$\text{second: } \ Pr([X-E(X)]^2 \ge t^2) = E([X-E(X)]^2)/t^2$</p><p>$\text{next: } \ E([X-E(X)]^2)/t^2 = Var(X)/ t^2$</p><p>$\large \text{finally: } \ Pr([X-E(X)]^2 \ge t^2) = Pr(\ |X-E(X)| \ge t\ ) = \frac{\large Var[X]}{\Large t^2}$</p><p><code class="language-plaintext highlighter-rouge">Using Chebyshev to bound Query Time:</code></p>\[\large P(\left|Q_x - E(Q_x)\right| &gt; t) \le \frac{\large n(\LARGE \frac{1}{m})(\large 1-\LARGE \frac{1}{m})}{t^2} \large &lt; \frac{E(X)}{t}\]<p>$\large n(1/m)(1 - 1/m) = np(1-p) = npq$</p><p><img data-src="https://raw.githubusercontent.com/adrianmnh/courses/mainBranch/assets/img\linebreak-fire.png" alt="" data-proofer-ignore></p><h1 id="universal-hash-function"><strong>Universal Hash Function</strong></h1><p>Let $U$ be a universe of keys and $H$ be a finite collection of hash functions $h:[u]⇒[m]$</p><p>$H$ is <code class="language-plaintext highlighter-rouge">universal</code> if</p><p><img data-src="https://raw.githubusercontent.com/adrianmnh/courses/mainBranch/assets/img\linebreak-fire.png" alt="" data-proofer-ignore></p><h2 id="chernoff-bound"><span class="mr-2"><strong>Chernoff Bound</strong></span><a href="#chernoff-bound" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Let $X_1, X_2, …, X_n$ be a Bernouli R.V. set $Pr{X_i=1}=P_i$, and can be written as $\large X = \sum_{i=1}^n X_i$ and $\delta \in R$, then:</p><ol><li>$\text{If } 0\le \delta &lt; 1,\large Pr{X &gt; (1 +\delta)(E[X])} \le \large{e}\Large^{\frac{1}{3}\delta^2E(X) } \normalsize = \Large \frac {\large 1}{\Large e^{\Large \frac{1}{3}\large\delta^2E(X)}}$<ul><li>if $\large c$ <code class="language-plaintext highlighter-rouge">is large</code>, then $\frac{1}{\large e^{\normalsize c}}$<code class="language-plaintext highlighter-rouge">is very small</code></ul><li>$\forall\ \delta &gt; 0, \large Pr{X\ge (1+\delta)(E[X])}\le \large \left( \frac{\large e^{\normalsize \delta}}{\large (1+\delta)^{\normalsize 1+\delta}} \right)^{\normalsize E(X)}$<ul><li>$Pr{x\ge (1+\delta)(E[X])}$ <code class="language-plaintext highlighter-rouge">is a bad event</code></ul></ol><p><code class="language-plaintext highlighter-rouge">We want to know:</code> $Pr(Y\ge B):$</p><p>Define $X_i = \begin{cases} 1, \ if\ i^{th }\text{ key maps to the block } ⇒\ Y = \large \sum_{i=1}^n X_i<br /> \ 0,\ ow\end{cases}$</p><p>Let $\delta=\Large\frac{1}{n}\normalsize-1, then$</p>\[\large Pr\{Y\ge B\}=Pr\{Y\ge (1+\left(\large\frac{1}{n}\normalsize- 1\right))E[Y]\}\] \[\large \le \left( \frac{e^{\normalsize\delta}}{(1+\delta)^{\normalsize1+\delta}}\right)^{\normalsize E(X)} = \left( \frac{e^{\normalsize\left(\frac{1}{n}\normalsize-1\right)}}{(1+\Large\frac{1}{n}\normalsize-1)^{\normalsize1+\Large\frac{1}{n}\normalsize-1}}\right)^{\normalsize E(X)}\]<p><img data-src="https://raw.githubusercontent.com/adrianmnh/courses/mainBranch/assets/img\linebreak-fire.png" alt="" data-proofer-ignore></p><h1 id="streaming-model">Streaming Model</h1><p>Used when:</p><ul><li>limited space<li>elements come one at a time<li>elements seen once may never appear again<li>results may be approximations</ul><p>Space for the whole stream: $m$</p><p>Goal:</p><p><strong>$log(m) \ or \ polylog(m)$</strong></p><p>To represent a single number of magnitude n, we need log n bits.</p><p><code class="language-plaintext highlighter-rouge">Number n -&gt; log n bits</code></p><h2 id="sampling-problem"><span class="mr-2">Sampling Problem</span><a href="#sampling-problem" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Given a stream and unknown integer S.</p><ol><li>At every point <code class="language-plaintext highlighter-rouge">i</code>, maintain a set A of size S containing elements from the stream <code class="language-plaintext highlighter-rouge">uniformly</code><li>Every element of the stream should have equal chance of being the the set</ol><h2 id="algorithm"><span class="mr-2">Algorithm</span><a href="#algorithm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>$S$ - random integer</p><p>$A$ - set of size S</p><p>$X_j$ - randomly chosen from $A_{i-1}$ → <code class="language-plaintext highlighter-rouge">any element from the current set with</code> $Prob=S/i$</p><ol><li>Put first $S$ elements from stream in set $A$<li>Let $A_i$ be the sample at time i<ol><li>for $i&gt;S:$<ol><li>swap $X_i$ with $X_j$ <code class="language-plaintext highlighter-rouge">current from stream with randomly chosen from set</code></ol></ol></ol><h2 id="claim"><span class="mr-2">Claim</span><a href="#claim" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>At every point $i$, $X_j$ is in the set $A_i$ with $Prob=S/i$</p><h2 id="proof-by-induction"><span class="mr-2">Proof By Induction</span><a href="#proof-by-induction" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><code class="language-plaintext highlighter-rouge">Base Case:</code> $i \leq S,\ Pr(X_j \text{ in } A_i)= 1$</p><p><code class="language-plaintext highlighter-rouge">Assume algorithm is correct for all i up to K:</code> $\ \forall \ 1\leq i\leq k$</p><p><code class="language-plaintext highlighter-rouge">By inductive hypothesis(IH):</code> This means $A_k={X_1, X_2, X_3, … , X_k}$ and every element is in this sample with $Pr = S/k$</p><p><code class="language-plaintext highlighter-rouge">Using these facts: </code></p><ol><li><code class="language-plaintext highlighter-rouge">given: Pr(A) ~ Pr(latest stream element will be placed in the set A)</code><ul><li>$Pr(X_{k+1} \text{ is an element of the set }A_{k+1})=S/K+1$</ul><li><code class="language-plaintext highlighter-rouge">probability that some element is in the new set, given that it wasn't in the previous iteration</code><ul><li>$Pr(X_j \text{ is an element of the set } A_{k+1}\mid X_j\text{ is not in }A_k)=0$</ul><li><code class="language-plaintext highlighter-rouge">probability that some element is in the new and the previous one is EQUAL TO (1 - probability that element is in previous but not in the new set)</code><ul><li>$Pr(X_j \in A_{k+1} \mid X_j \in A_k) = 1 - Pr(X_j \notin A_{k+1} \mid X_j \in A_k)$`</ul><li><code class="language-plaintext highlighter-rouge">Pr(some element is in the new set) = Pr(element is in new set\|element is in previous set).Pr(element is in previous set) + Pr(element is in new set\|element is not in previous set).Pr(element is not in previous set)</code><ul><li>$Pr(A) = Pr(A\mid B) Pr(B) + Pr(A\mid B^c).Pr(B^c)$</ul></ol><div class="table-wrapper"><table><tbody><tr><td>So, $\text{Pr(element is new set<td>element is not in previous set) = 0}$</table></div><p>Then, $Pr(X_j \in A_{k+1} ) = Pr(X_j \in A_{k+1}\mid X_j \in A_k).Pr(X_j \in A_k) + 0*Pr(X_j \notin A_k)$</p><p>$Pr(X_j\in A_{k+1}\mid X_j \in A_k) = 1-Pr(X_j \notin A_{k+1}\mid X_j\in A_k)$</p><p>$\text{Pr(element is not in new set given that it is in the previous set)=Pr(element got booted in the current iteration }\times \text{which element got booted)} = S/(k+1) \times 1/S$</p><p>$Pr(X_j \in A_{k+1} \mid X_j \in A_k) = 1-S/(k+1) \times 1/S = k/(k+1)$</p><p>$\text{Finally, }Pr(X_j \in A_{k+1} ) = k/(k+1) \times S/k + 0 = \Large \frac{S}{k+1}$</p><p><img data-src="https://raw.githubusercontent.com/adrianmnh/courses/mainBranch/assets/img\linebreak-fire.png" alt="" data-proofer-ignore></p></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/courses/posts/SettingUpDocker/">Setting up Docker Containers for SQL</a><li><a href="/courses/posts/due/">Important Dates</a><li><a href="/courses/posts/dm-course-overview/">CSCI 381 - Data Modeling Course Overview</a><li><a href="/courses/posts/dm-01/">CSCI 381 - Data Modeling and Advanced Systems 1</a><li><a href="/courses/posts/dm-02/">CSCI 381 - Data Modeling and Advanced Systems 2</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/courses/tags/class01/">class01</a> <a class="post-tag" href="/courses/tags/data-governance/">Data Governance</a> <a class="post-tag" href="/courses/tags/data-modeling/">Data Modeling</a> <a class="post-tag" href="/courses/tags/data-quality/">Data Quality</a> <a class="post-tag" href="/courses/tags/course/">Course</a> <a class="post-tag" href="/courses/tags/csci381/">CSCI381</a> <a class="post-tag" href="/courses/tags/docker/">docker</a> <a class="post-tag" href="/courses/tags/mysql/">MySQL</a> <a class="post-tag" href="/courses/tags/postgresql/">PostgreSQL</a> <a class="post-tag" href="/courses/tags/sqlserver/">SQLServer</a></div></div></div></div></div><footer class="row pl-3 pr-3"><div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://adrianmnh.github.io">Adrian Miguel Noa</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/courses/tags/class01/">class01</a> <a class="post-tag" href="/courses/tags/data-governance/">Data Governance</a> <a class="post-tag" href="/courses/tags/data-modeling/">Data Modeling</a> <a class="post-tag" href="/courses/tags/data-quality/">Data Quality</a> <a class="post-tag" href="/courses/tags/course/">Course</a> <a class="post-tag" href="/courses/tags/csci381/">CSCI381</a> <a class="post-tag" href="/courses/tags/docker/">docker</a> <a class="post-tag" href="/courses/tags/mysql/">MySQL</a> <a class="post-tag" href="/courses/tags/postgresql/">PostgreSQL</a> <a class="post-tag" href="/courses/tags/sqlserver/">SQLServer</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a><div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-animation="true" data-autohide="false"><div class="toast-header"> <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close"> <span aria-hidden="true">&times;</span> </button></div><div class="toast-body text-center pt-0"><p class="pl-2 pr-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></div><script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/courses/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/courses/assets/js/dist/page.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/courses/app.js"></script>
